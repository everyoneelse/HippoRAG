#!/usr/bin/env python3
"""
HippoRAGçŸ¥è¯†å›¾è°±ä¿å­˜åŠŸèƒ½æ¼”ç¤º
"""

import os
import argparse
from src.hipporag.HippoRAG import HippoRAG
from src.hipporag.utils.config_utils import BaseConfig

def demo_save_knowledge_graph(embedding_model_path=None, openai_api_key=None):
    """æ¼”ç¤ºçŸ¥è¯†å›¾è°±ä¿å­˜åŠŸèƒ½"""
    
    print("ğŸš€ HippoRAGçŸ¥è¯†å›¾è°±ä¿å­˜åŠŸèƒ½æ¼”ç¤º")
    print("=" * 50)
    
    # è®¾ç½® API Key
    if openai_api_key:
        os.environ['OPENAI_API_KEY'] = openai_api_key
        print("ğŸ”‘ ä½¿ç”¨æä¾›çš„ OpenAI API Key")
    elif not os.getenv('OPENAI_API_KEY'):
        print("âš ï¸  æœªè®¾ç½® OPENAI_API_KEYï¼Œå¦‚æœä½¿ç”¨ OpenAI æ¨¡å‹å¯èƒ½ä¼šå¤±è´¥")
        print("ğŸ’¡ æç¤º: å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¾ç½®:")
        print("   æ–¹æ³•1: export OPENAI_API_KEY='your-api-key'")
        print("   æ–¹æ³•2: python demo_save_kg.py --openai_api_key your-api-key")
    else:
        # æ˜¾ç¤ºå·²è®¾ç½®çš„ API Keyï¼ˆéƒ¨åˆ†é®è”½ï¼‰
        api_key = os.getenv('OPENAI_API_KEY')
        masked_key = f"{api_key[:8]}...{api_key[-4:]}" if len(api_key) > 12 else "***"
        print(f"âœ… å·²è®¾ç½® OPENAI_API_KEY: {masked_key}")
    
    # å‡†å¤‡ç¤ºä¾‹æ•°æ®
    docs = [
        "è‹¹æœå…¬å¸æ˜¯ä¸€å®¶ç¾å›½ç§‘æŠ€å…¬å¸ã€‚",
        "iPhoneæ˜¯è‹¹æœå…¬å¸çš„ä¸»è¦äº§å“ã€‚",
        "å²è’‚å¤«Â·ä¹”å¸ƒæ–¯æ˜¯è‹¹æœå…¬å¸çš„åˆ›å§‹äººä¹‹ä¸€ã€‚",
        "è‹¹æœå…¬å¸æ€»éƒ¨ä½äºåŠ åˆ©ç¦å°¼äºšå·åº“æ¯”è’‚è¯ºã€‚",
        "Macç”µè„‘ä¹Ÿæ˜¯è‹¹æœå…¬å¸çš„é‡è¦äº§å“çº¿ã€‚",
        "è‹¹æœå…¬å¸åœ¨å…¨çƒæ‹¥æœ‰ä¼—å¤šé›¶å”®åº—ã€‚"
    ]
    
    # ç¡®å®šåµŒå…¥æ¨¡å‹è·¯å¾„
    embedding_model_name = embedding_model_path if embedding_model_path else 'nvidia/NV-Embed-v2'
    
    if embedding_model_path:
        print(f"ğŸ”§ ä½¿ç”¨æœ¬åœ°åµŒå…¥æ¨¡å‹è·¯å¾„: {embedding_model_name}")
    
    # é…ç½®HippoRAG
    config = BaseConfig(
        save_dir='demo_outputs',
        llm_name='gpt-4o-mini',
        embedding_model_name=embedding_model_name,
        dataset='demo',
        force_index_from_scratch=True,  # é‡æ–°æ„å»º
        force_openie_from_scratch=True
    )
    
    print("ğŸ“ åˆå§‹åŒ–HippoRAG...")
    hipporag = HippoRAG(global_config=config)
    
    print("ğŸ” æ„å»ºçŸ¥è¯†å›¾è°±...")
    hipporag.index(docs)
    
    print("ğŸ“Š çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯:")
    graph_info = hipporag.get_graph_info()
    for key, value in graph_info.items():
        print(f"  {key}: {value}")
    
    print("\nğŸ’¾ ä¿å­˜çŸ¥è¯†å›¾è°±...")
    
    # 1. é»˜è®¤ä¿å­˜ï¼ˆå·²è‡ªåŠ¨å®Œæˆï¼‰
    print("âœ… 1. é»˜è®¤æ ¼å¼ä¿å­˜å®Œæˆï¼ˆpickleæ ¼å¼ï¼‰")
    
    # 2. å¯¼å‡ºä¸ºJSONæ ¼å¼
    json_path = hipporag.export_knowledge_graph('json', 'demo_graph.json')
    print(f"âœ… 2. JSONæ ¼å¼å¯¼å‡ºå®Œæˆ: {json_path}")
    
    # 3. å¯¼å‡ºä¸ºGraphMLæ ¼å¼ï¼ˆå¯ç”¨äºGephiç­‰å›¾åˆ†æå·¥å…·ï¼‰
    try:
        graphml_path = hipporag.export_knowledge_graph('graphml', 'demo_graph.graphml')
        print(f"âœ… 3. GraphMLæ ¼å¼å¯¼å‡ºå®Œæˆ: {graphml_path}")
    except Exception as e:
        print(f"âš ï¸  3. GraphMLæ ¼å¼å¯¼å‡ºè·³è¿‡: {str(e)}")
    
    # 4. å¯¼å‡ºOpenIEç»“æœ
    openie_path = hipporag.export_openie_results('demo_openie.json')
    print(f"âœ… 4. OpenIEç»“æœå¯¼å‡ºå®Œæˆ: {openie_path}")
    
    # 5. å¯¼å‡ºå®Œæ•´çŸ¥è¯†åº“
    print("\nğŸ¯ å¯¼å‡ºå®Œæ•´çŸ¥è¯†åº“...")
    saved_files = hipporag.save_complete_knowledge_base('complete_export')
    print("âœ… 5. å®Œæ•´çŸ¥è¯†åº“å¯¼å‡ºå®Œæˆ!")
    
    print(f"\nğŸ“ å¯¼å‡ºçš„æ–‡ä»¶:")
    for file_type, file_path in saved_files.items():
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path) / 1024  # KB
            print(f"  {file_type}: {file_path} ({file_size:.1f} KB)")
    
    print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
    print(f"ğŸ“‚ æ‚¨å¯ä»¥åœ¨ä»¥ä¸‹ä½ç½®æ‰¾åˆ°ä¿å­˜çš„æ–‡ä»¶:")
    print(f"  - å·¥ä½œç›®å½•: {hipporag.working_dir}")
    print(f"  - å¯¼å‡ºç›®å½•: complete_export/")
    
    # æ¼”ç¤ºå¦‚ä½•é‡æ–°åŠ è½½çŸ¥è¯†å›¾è°±
    print(f"\nğŸ”„ æ¼”ç¤ºé‡æ–°åŠ è½½çŸ¥è¯†å›¾è°±...")
    
    # åˆ›å»ºæ–°çš„HippoRAGå®ä¾‹ï¼ˆä½¿ç”¨ç›¸åŒé…ç½®ï¼‰
    config_reload = BaseConfig(
        save_dir='demo_outputs',
        llm_name='gpt-4o-mini',
        embedding_model_name=embedding_model_name,  # ä½¿ç”¨ç›¸åŒçš„åµŒå…¥æ¨¡å‹è·¯å¾„
        dataset='demo',
        force_index_from_scratch=False,  # ä½¿ç”¨å·²ä¿å­˜çš„æ•°æ®
        force_openie_from_scratch=False
    )
    
    hipporag_reloaded = HippoRAG(global_config=config_reload)
    
    # æµ‹è¯•æ£€ç´¢åŠŸèƒ½
    queries = ["è‹¹æœå…¬å¸çš„åˆ›å§‹äººæ˜¯è°ï¼Ÿ", "iPhoneæ˜¯ä»€ä¹ˆäº§å“ï¼Ÿ"]
    
    print("ğŸ” æµ‹è¯•æ£€ç´¢åŠŸèƒ½...")
    retrieval_results = hipporag_reloaded.retrieve(queries=queries, num_to_retrieve=2)
    
    for i, result in enumerate(retrieval_results):
        print(f"\næŸ¥è¯¢ {i+1}: {result.question}")
        print("æ£€ç´¢ç»“æœ:")
        for j, doc in enumerate(result.docs):
            print(f"  {j+1}. {doc[:100]}...")
    
    print(f"\nâœ… çŸ¥è¯†å›¾è°±é‡æ–°åŠ è½½å’Œæ£€ç´¢æµ‹è¯•æˆåŠŸ!")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="HippoRAGçŸ¥è¯†å›¾è°±ä¿å­˜åŠŸèƒ½æ¼”ç¤º")
    parser.add_argument('--embedding_path', type=str, default=None, 
                       help='æœ¬åœ°åµŒå…¥æ¨¡å‹è·¯å¾„ï¼ˆå¦‚æœæ¨¡å‹ä¸‹è½½åœ¨æœ¬åœ°ï¼‰')
    parser.add_argument('--openai_api_key', type=str, default=None,
                       help='OpenAI API Keyï¼ˆä¹Ÿå¯é€šè¿‡ç¯å¢ƒå˜é‡ OPENAI_API_KEY è®¾ç½®ï¼‰')
    
    args = parser.parse_args()
    
    demo_save_knowledge_graph(args.embedding_path, args.openai_api_key)