#!/usr/bin/env python3
"""
å®Œå…¨ç¦»çº¿è¿è¡Œ HippoRAG çš„ç¤ºä¾‹è„šæœ¬
ä½¿ç”¨ç¦»çº¿è¡¥ä¸ç¡®ä¿ä¸ä¼šæœ‰ä»»ä½•ç½‘ç»œè¯·æ±‚
"""

# ç¬¬ä¸€æ­¥ï¼šåº”ç”¨ç¦»çº¿è¡¥ä¸ï¼ˆå¿…é¡»åœ¨å¯¼å…¥å…¶ä»–æ¨¡å—ä¹‹å‰ï¼‰
print("ğŸš€ HippoRAG å®Œå…¨ç¦»çº¿è¿è¡Œ")
print("=" * 50)

import hipporag_offline_patch  # åº”ç”¨ç¦»çº¿è¡¥ä¸

# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥ HippoRAG ç›¸å…³æ¨¡å—
import os
import argparse
from src.hipporag.HippoRAG import HippoRAG
from src.hipporag.utils.config_utils import BaseConfig

def run_offline_demo(model_path, api_key=None):
    """è¿è¡Œç¦»çº¿æ¼”ç¤º"""
    
    print(f"\nğŸ“ ä½¿ç”¨æœ¬åœ°æ¨¡å‹: {model_path}")
    
    # éªŒè¯æ¨¡å‹è·¯å¾„
    if not os.path.exists(model_path):
        print(f"âŒ é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return False
    
    # æ£€æŸ¥å…³é”®æ–‡ä»¶
    required_files = ['config.json', 'tokenizer_config.json']
    missing_files = []
    
    for file in required_files:
        if not os.path.exists(os.path.join(model_path, file)):
            missing_files.append(file)
    
    if missing_files:
        print(f"âš ï¸  è­¦å‘Š: ç¼ºå¤±æ–‡ä»¶ {missing_files}ï¼Œå¯èƒ½å½±å“åŠ è½½")
    else:
        print("âœ… æ¨¡å‹æ–‡ä»¶æ£€æŸ¥é€šè¿‡")
    
    # è®¾ç½® API keyï¼ˆå¦‚æœæä¾›ï¼‰
    if api_key:
        os.environ['OPENAI_API_KEY'] = api_key
        print("ğŸ”‘ å·²è®¾ç½® API Key")
    
    # é…ç½® HippoRAG
    config = BaseConfig(
        save_dir='offline_outputs',
        llm_name='gpt-4o-mini',
        embedding_model_name=model_path,  # ä½¿ç”¨æœ¬åœ°è·¯å¾„
        dataset='offline_test',
        force_index_from_scratch=True,
        force_openie_from_scratch=True
    )
    
    print("\nğŸ”§ åˆå§‹åŒ– HippoRAG...")
    try:
        hipporag = HippoRAG(global_config=config)
        print("âœ… HippoRAG åˆå§‹åŒ–æˆåŠŸï¼ˆå®Œå…¨ç¦»çº¿ï¼‰")
    except Exception as e:
        print(f"âŒ HippoRAG åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    docs = [
        "Python æ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ã€‚",
        "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯ã€‚",
        "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œæ¨¡å¼è¯†åˆ«ã€‚",
        "è‡ªç„¶è¯­è¨€å¤„ç†å¸®åŠ©è®¡ç®—æœºç†è§£äººç±»è¯­è¨€ã€‚",
        "çŸ¥è¯†å›¾è°±ç”¨äºè¡¨ç¤ºå®ä½“ä¹‹é—´çš„å…³ç³»ã€‚"
    ]
    
    print(f"\nğŸ“š å¼€å§‹æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆ{len(docs)} ä¸ªæ–‡æ¡£ï¼‰...")
    try:
        hipporag.index(docs)
        print("âœ… çŸ¥è¯†å›¾è°±æ„å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ çŸ¥è¯†å›¾è°±æ„å»ºå¤±è´¥: {e}")
        return False
    
    # è·å–å›¾è°±ç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š çŸ¥è¯†å›¾è°±ç»Ÿè®¡:")
    try:
        graph_info = hipporag.get_graph_info()
        for key, value in graph_info.items():
            print(f"  {key}: {value}")
    except Exception as e:
        print(f"âš ï¸  æ— æ³•è·å–å›¾è°±ç»Ÿè®¡: {e}")
    
    # å¯¼å‡ºçŸ¥è¯†å›¾è°±
    print("\nğŸ’¾ å¯¼å‡ºçŸ¥è¯†å›¾è°±...")
    try:
        # å¯¼å‡º JSON æ ¼å¼
        json_path = hipporag.export_knowledge_graph('json', 'offline_graph.json')
        print(f"âœ… JSON æ ¼å¼å¯¼å‡º: {json_path}")
        
        # å¯¼å‡º OpenIE ç»“æœ
        openie_path = hipporag.export_openie_results('offline_openie.json')
        print(f"âœ… OpenIE ç»“æœå¯¼å‡º: {openie_path}")
        
        # å¯¼å‡ºå®Œæ•´çŸ¥è¯†åº“
        saved_files = hipporag.save_complete_knowledge_base('offline_complete')
        print(f"âœ… å®Œæ•´çŸ¥è¯†åº“å¯¼å‡º: {len(saved_files)} ä¸ªæ–‡ä»¶")
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ£€ç´¢åŠŸèƒ½
    print("\nğŸ” æµ‹è¯•æ£€ç´¢åŠŸèƒ½...")
    try:
        queries = ["ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ", "æ·±åº¦å­¦ä¹ å¦‚ä½•å·¥ä½œï¼Ÿ"]
        results = hipporag.retrieve(queries, num_to_retrieve=2)
        
        for i, result in enumerate(results):
            print(f"\næŸ¥è¯¢ {i+1}: {result.question}")
            print("æ£€ç´¢ç»“æœ:")
            for j, doc in enumerate(result.docs):
                print(f"  {j+1}. {doc[:50]}...")
        
        print("âœ… æ£€ç´¢åŠŸèƒ½æµ‹è¯•æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ æ£€ç´¢åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print(f"\nğŸ‰ ç¦»çº¿æ¼”ç¤ºå®Œæˆ!")
    print("ğŸ“‚ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - offline_graph.json (çŸ¥è¯†å›¾è°±)")
    print("  - offline_openie.json (OpenIE ç»“æœ)")
    print("  - offline_complete/ (å®Œæ•´çŸ¥è¯†åº“)")
    
    return True

def main():
    parser = argparse.ArgumentParser(description="HippoRAG å®Œå…¨ç¦»çº¿è¿è¡Œæ¼”ç¤º")
    parser.add_argument('--model_path', type=str, 
                       default='/mnt/data/hy/GPT/models/nvidia/NV-Embed-v2',
                       help='æœ¬åœ°åµŒå…¥æ¨¡å‹è·¯å¾„')
    parser.add_argument('--api_key', type=str, default=None,
                       help='OpenAI API Keyï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    # è¿è¡Œç¦»çº¿æ¼”ç¤º
    success = run_offline_demo(args.model_path, args.api_key)
    
    if success:
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼HippoRAG å¯ä»¥å®Œå…¨ç¦»çº¿è¿è¡Œã€‚")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯ã€‚")
    
    print("\nğŸ’¡ æç¤º:")
    print("  - ç¡®ä¿æ¨¡å‹æ–‡ä»¶å®Œæ•´")
    print("  - ä½¿ç”¨ --api_key å‚æ•°è®¾ç½® OpenAI API Keyï¼ˆå¦‚éœ€è¦ï¼‰")
    print("  - æ‰€æœ‰æ“ä½œéƒ½åœ¨ç¦»çº¿æ¨¡å¼ä¸‹å®Œæˆï¼Œæ— ç½‘ç»œè¯·æ±‚")

if __name__ == "__main__":
    main()