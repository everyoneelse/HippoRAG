# ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„çš„è¯´æ˜

## æ¦‚è¿°

å¦‚æœæ‚¨å·²ç»å°† `nvidia/NV-Embed-v2` æˆ–å…¶ä»–åµŒå…¥æ¨¡å‹ä¸‹è½½åˆ°æœ¬åœ°ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åœ¨HippoRAGä¸­ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„ã€‚

## ğŸ”§ ä¿®æ”¹æ–¹æ³•

### 1. ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°ï¼ˆæ¨èï¼‰

#### export_knowledge_graph.py
```bash
# ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
python export_knowledge_graph.py --embedding_path /path/to/your/nvidia-NV-Embed-v2

# å®Œæ•´ç¤ºä¾‹
python export_knowledge_graph.py \
    --dataset sample \
    --embedding_path /home/user/models/nvidia-NV-Embed-v2 \
    --export_format json
```

#### demo_save_kg.py
```bash
# ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
python demo_save_kg.py --embedding_path /path/to/your/nvidia-NV-Embed-v2
```

### 2. ç›´æ¥åœ¨ä»£ç ä¸­ä¿®æ”¹

å¦‚æœæ‚¨æƒ³ç›´æ¥ä¿®æ”¹ä»£ç ï¼Œå¯ä»¥åœ¨é…ç½®ä¸­æŒ‡å®šæœ¬åœ°è·¯å¾„ï¼š

```python
from src.hipporag.HippoRAG import HippoRAG
from src.hipporag.utils.config_utils import BaseConfig

# é…ç½®æœ¬åœ°æ¨¡å‹è·¯å¾„
config = BaseConfig(
    save_dir='outputs',
    llm_name='gpt-4o-mini',
    embedding_model_name='/path/to/your/nvidia-NV-Embed-v2',  # ä½¿ç”¨æœ¬åœ°è·¯å¾„
    dataset='my_dataset'
)

hipporag = HippoRAG(global_config=config)
```

## ğŸ“ å¸¸è§çš„æœ¬åœ°æ¨¡å‹è·¯å¾„ç¤ºä¾‹

### Linux/Mac
```bash
# å¦‚æœæ¨¡å‹åœ¨ç”¨æˆ·ç›®å½•ä¸‹
--embedding_path /home/username/models/nvidia-NV-Embed-v2

# å¦‚æœæ¨¡å‹åœ¨é¡¹ç›®ç›®å½•ä¸‹
--embedding_path ./models/nvidia-NV-Embed-v2

# å¦‚æœæ¨¡å‹åœ¨å…±äº«ç›®å½•ä¸‹
--embedding_path /opt/models/nvidia-NV-Embed-v2
```

### Windows
```bash
# å¦‚æœæ¨¡å‹åœ¨ç”¨æˆ·ç›®å½•ä¸‹
--embedding_path C:\Users\username\models\nvidia-NV-Embed-v2

# å¦‚æœæ¨¡å‹åœ¨é¡¹ç›®ç›®å½•ä¸‹
--embedding_path .\models\nvidia-NV-Embed-v2
```

## ğŸ” å¦‚ä½•æ‰¾åˆ°æ‚¨çš„æ¨¡å‹è·¯å¾„

### 1. é€šè¿‡Hugging Faceç¼“å­˜
å¦‚æœæ‚¨ä¹‹å‰ä½¿ç”¨è¿‡è¯¥æ¨¡å‹ï¼Œå®ƒå¯èƒ½è¢«ç¼“å­˜åœ¨ï¼š

```bash
# Linux/Mac
~/.cache/huggingface/hub/models--nvidia--NV-Embed-v2

# Windows
C:\Users\{username}\.cache\huggingface\hub\models--nvidia--NV-Embed-v2
```

### 2. æ‰‹åŠ¨ä¸‹è½½çš„æ¨¡å‹
å¦‚æœæ‚¨æ‰‹åŠ¨ä¸‹è½½äº†æ¨¡å‹ï¼Œè·¯å¾„å°±æ˜¯æ‚¨ä¿å­˜æ¨¡å‹æ–‡ä»¶çš„ç›®å½•ã€‚

### 3. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ç¡®ä¿æ‚¨çš„æ¨¡å‹ç›®å½•åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š
```
nvidia-NV-Embed-v2/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin æˆ– model.safetensors
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ tokenizer_config.json
â””â”€â”€ vocab.txt
```

## ğŸš€ å®Œæ•´ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šå¯¼å‡ºçŸ¥è¯†å›¾è°±ï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰
```bash
python export_knowledge_graph.py \
    --dataset sample \
    --llm_name gpt-4o-mini \
    --embedding_path /home/user/models/nvidia-NV-Embed-v2 \
    --export_format all \
    --export_dir my_exports
```

### ç¤ºä¾‹2ï¼šæ¼”ç¤ºä¿å­˜åŠŸèƒ½ï¼ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰
```bash
python demo_save_kg.py --embedding_path /home/user/models/nvidia-NV-Embed-v2
```

### ç¤ºä¾‹3ï¼šåœ¨main.pyä¸­ä½¿ç”¨æœ¬åœ°æ¨¡å‹
```bash
python main.py \
    --dataset sample \
    --llm_name gpt-4o-mini \
    --embedding_name /home/user/models/nvidia-NV-Embed-v2
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **è·¯å¾„æ ¼å¼**ï¼š
   - ä½¿ç”¨ç»å¯¹è·¯å¾„æ›´å¯é 
   - ç¡®ä¿è·¯å¾„ä¸­æ²¡æœ‰ç©ºæ ¼ï¼Œæˆ–è€…ç”¨å¼•å·åŒ…å›´è·¯å¾„
   - Windowsç”¨æˆ·æ³¨æ„ä½¿ç”¨æ­£ç¡®çš„è·¯å¾„åˆ†éš”ç¬¦

2. **æƒé™é—®é¢˜**ï¼š
   - ç¡®ä¿Pythonè¿›ç¨‹æœ‰è¯»å–æ¨¡å‹æ–‡ä»¶çš„æƒé™
   - å¦‚æœæ¨¡å‹åœ¨ç³»ç»Ÿç›®å½•ä¸‹ï¼Œå¯èƒ½éœ€è¦ç®¡ç†å‘˜æƒé™

3. **æ¨¡å‹å®Œæ•´æ€§**ï¼š
   - ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„æ¨¡å‹æ–‡ä»¶éƒ½å­˜åœ¨
   - æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®Œæ•´ä¸‹è½½

4. **å…¼å®¹æ€§**ï¼š
   - ç¡®ä¿æœ¬åœ°æ¨¡å‹ç‰ˆæœ¬ä¸HippoRAGå…¼å®¹
   - å»ºè®®ä½¿ç”¨å®˜æ–¹å‘å¸ƒçš„æ¨¡å‹ç‰ˆæœ¬

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯åŠè§£å†³æ–¹æ³•

1. **æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶**
   ```
   é”™è¯¯: No such file or directory
   è§£å†³: æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„
   ```

2. **æƒé™è¢«æ‹’ç»**
   ```
   é”™è¯¯: Permission denied
   è§£å†³: æ£€æŸ¥æ–‡ä»¶æƒé™ï¼Œæˆ–ä½¿ç”¨sudoè¿è¡Œï¼ˆä¸æ¨èï¼‰
   ```

3. **æ¨¡å‹åŠ è½½å¤±è´¥**
   ```
   é”™è¯¯: Can't load model
   è§£å†³: æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§ï¼Œé‡æ–°ä¸‹è½½æ¨¡å‹
   ```

### éªŒè¯æ¨¡å‹è·¯å¾„
æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹Pythonä»£ç éªŒè¯æ¨¡å‹è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼š

```python
import os
from transformers import AutoModel, AutoTokenizer

model_path = "/path/to/your/nvidia-NV-Embed-v2"

# æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
if os.path.exists(model_path):
    print(f"âœ… æ¨¡å‹è·¯å¾„å­˜åœ¨: {model_path}")
    
    # å°è¯•åŠ è½½æ¨¡å‹
    try:
        tokenizer = AutoTokenizer.from_pretrained(model_path)
        model = AutoModel.from_pretrained(model_path)
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
else:
    print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
```

## ğŸ“ ç¯å¢ƒå˜é‡æ–¹å¼ï¼ˆå¯é€‰ï¼‰

æ‚¨ä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡æ¥æŒ‡å®šæ¨¡å‹è·¯å¾„ï¼š

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export EMBEDDING_MODEL_PATH="/path/to/your/nvidia-NV-Embed-v2"

# ç„¶ååœ¨ä»£ç ä¸­ä½¿ç”¨
python export_knowledge_graph.py --embedding_path $EMBEDDING_MODEL_PATH
```

è¿™æ ·æ‚¨å°±å¯ä»¥çµæ´»åœ°ä½¿ç”¨æœ¬åœ°ä¸‹è½½çš„åµŒå…¥æ¨¡å‹äº†ï¼ğŸ‰