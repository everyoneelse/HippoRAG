#!/usr/bin/env python3
"""
çŸ¥è¯†å›¾è°±å¯¼å‡ºç¤ºä¾‹è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨HippoRAGçš„å„ç§çŸ¥è¯†å›¾è°±ä¿å­˜å’Œå¯¼å‡ºåŠŸèƒ½
"""

import os
import json
import argparse
from src.hipporag.HippoRAG import HippoRAG
from src.hipporag.utils.config_utils import BaseConfig

def main():
    parser = argparse.ArgumentParser(description="å¯¼å‡ºHippoRAGçŸ¥è¯†å›¾è°±")
    parser.add_argument('--dataset', type=str, default='sample', help='æ•°æ®é›†åç§°')
    parser.add_argument('--llm_name', type=str, default='gpt-4o-mini', help='LLMæ¨¡å‹åç§°')
    parser.add_argument('--embedding_name', type=str, default='nvidia/NV-Embed-v2', help='åµŒå…¥æ¨¡å‹åç§°')
    parser.add_argument('--save_dir', type=str, default='outputs', help='ä¿å­˜ç›®å½•')
    parser.add_argument('--export_format', type=str, choices=['json', 'graphml', 'gml', 'all'], 
                       default='all', help='å¯¼å‡ºæ ¼å¼')
    parser.add_argument('--export_dir', type=str, default='knowledge_exports', help='å¯¼å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # è®¾ç½®è·¯å¾„
    dataset_name = args.dataset
    save_dir = os.path.join(args.save_dir, dataset_name)
    export_dir = args.export_dir
    
    # ç¡®ä¿å¯¼å‡ºç›®å½•å­˜åœ¨
    os.makedirs(export_dir, exist_ok=True)
    
    print(f"ğŸš€ å¼€å§‹å¯¼å‡ºçŸ¥è¯†å›¾è°±...")
    print(f"ğŸ“ æ•°æ®é›†: {dataset_name}")
    print(f"ğŸ¤– LLMæ¨¡å‹: {args.llm_name}")
    print(f"ğŸ”¢ åµŒå…¥æ¨¡å‹: {args.embedding_name}")
    print(f"ğŸ“‚ å¯¼å‡ºç›®å½•: {export_dir}")
    
    # é…ç½®HippoRAG
    config = BaseConfig(
        save_dir=save_dir,
        llm_name=args.llm_name,
        embedding_model_name=args.embedding_name,
        dataset=dataset_name,
        force_index_from_scratch=False,  # ä½¿ç”¨å·²æœ‰çš„ç´¢å¼•
        force_openie_from_scratch=False
    )
    
    # åˆå§‹åŒ–HippoRAGå®ä¾‹
    hipporag = HippoRAG(global_config=config)
    
    # å¦‚æœæ²¡æœ‰ç°æœ‰çš„çŸ¥è¯†å›¾è°±ï¼Œå…ˆåˆ›å»ºä¸€ä¸ªç®€å•çš„ç¤ºä¾‹
    if not os.path.exists(hipporag._graph_pickle_filename):
        print("âš ï¸  æœªæ‰¾åˆ°ç°æœ‰çŸ¥è¯†å›¾è°±ï¼Œåˆ›å»ºç¤ºä¾‹æ•°æ®...")
        
        # ç¤ºä¾‹æ–‡æ¡£
        docs = [
            "åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½ã€‚",
            "ä¸­å›½æ˜¯ä¸€ä¸ªæ‹¥æœ‰æ‚ ä¹…å†å²çš„å›½å®¶ã€‚",
            "é•¿åŸæ˜¯ä¸­å›½è‘—åçš„å¤å»ºç­‘ã€‚",
            "æ•…å®«ä½äºåŒ—äº¬å¸‚ä¸­å¿ƒã€‚",
            "å¤©å®‰é—¨å¹¿åœºæ˜¯ä¸–ç•Œä¸Šæœ€å¤§çš„åŸå¸‚å¹¿åœºä¹‹ä¸€ã€‚"
        ]
        
        # ç´¢å¼•æ–‡æ¡£
        hipporag.index(docs)
        print("âœ… ç¤ºä¾‹çŸ¥è¯†å›¾è°±åˆ›å»ºå®Œæˆï¼")
    
    # å‡†å¤‡æ£€ç´¢å¯¹è±¡
    if not hipporag.ready_to_retrieve:
        hipporag.prepare_retrieval_objects()
    
    # å¯¼å‡ºçŸ¥è¯†å›¾è°±
    print("\nğŸ“Š çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯:")
    graph_info = hipporag.get_graph_info()
    for key, value in graph_info.items():
        print(f"  {key}: {value}")
    
    print(f"\nğŸ’¾ å¼€å§‹å¯¼å‡ºçŸ¥è¯†å›¾è°±...")
    
    exported_files = []
    
    if args.export_format == 'all':
        # å¯¼å‡ºæ‰€æœ‰æ ¼å¼
        formats = ['json', 'graphml', 'gml']
        for fmt in formats:
            try:
                output_path = os.path.join(export_dir, f"knowledge_graph_{dataset_name}.{fmt}")
                exported_path = hipporag.export_knowledge_graph(fmt, output_path)
                exported_files.append(exported_path)
                print(f"âœ… {fmt.upper()}æ ¼å¼å¯¼å‡ºå®Œæˆ: {exported_path}")
            except Exception as e:
                print(f"âŒ {fmt.upper()}æ ¼å¼å¯¼å‡ºå¤±è´¥: {str(e)}")
    else:
        # å¯¼å‡ºæŒ‡å®šæ ¼å¼
        try:
            output_path = os.path.join(export_dir, f"knowledge_graph_{dataset_name}.{args.export_format}")
            exported_path = hipporag.export_knowledge_graph(args.export_format, output_path)
            exported_files.append(exported_path)
            print(f"âœ… {args.export_format.upper()}æ ¼å¼å¯¼å‡ºå®Œæˆ: {exported_path}")
        except Exception as e:
            print(f"âŒ {args.export_format.upper()}æ ¼å¼å¯¼å‡ºå¤±è´¥: {str(e)}")
    
    # å¯¼å‡ºOpenIEç»“æœ
    try:
        openie_path = os.path.join(export_dir, f"openie_results_{dataset_name}.json")
        exported_path = hipporag.export_openie_results(openie_path)
        exported_files.append(exported_path)
        print(f"âœ… OpenIEç»“æœå¯¼å‡ºå®Œæˆ: {exported_path}")
    except Exception as e:
        print(f"âŒ OpenIEç»“æœå¯¼å‡ºå¤±è´¥: {str(e)}")
    
    # å¯¼å‡ºå®Œæ•´çŸ¥è¯†åº“
    try:
        print(f"\nğŸ¯ å¯¼å‡ºå®Œæ•´çŸ¥è¯†åº“...")
        saved_files = hipporag.save_complete_knowledge_base(export_dir)
        print(f"âœ… å®Œæ•´çŸ¥è¯†åº“å¯¼å‡ºå®Œæˆ!")
        print(f"ğŸ“‹ å¯¼å‡ºæ‘˜è¦: {saved_files['summary']}")
        
        # æ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯
        with open(saved_files['summary'], 'r', encoding='utf-8') as f:
            summary = json.load(f)
        
        print(f"\nğŸ“ˆ å¯¼å‡ºæ‘˜è¦:")
        print(f"  å¯¼å‡ºæ—¶é—´: {summary['export_timestamp']}")
        print(f"  å¯¼å‡ºç›®å½•: {summary['export_directory']}")
        print(f"  LLMæ¨¡å‹: {summary['configuration']['llm_model']}")
        print(f"  åµŒå…¥æ¨¡å‹: {summary['configuration']['embedding_model']}")
        print(f"  æ•°æ®é›†: {summary['configuration']['dataset']}")
        
        print(f"\nğŸ“ å¯¼å‡ºçš„æ–‡ä»¶:")
        for file_type, file_path in saved_files.items():
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path) / 1024  # KB
                print(f"  {file_type}: {file_path} ({file_size:.1f} KB)")
        
    except Exception as e:
        print(f"âŒ å®Œæ•´çŸ¥è¯†åº“å¯¼å‡ºå¤±è´¥: {str(e)}")
    
    print(f"\nğŸ‰ çŸ¥è¯†å›¾è°±å¯¼å‡ºå®Œæˆ!")
    print(f"ğŸ“‚ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°: {export_dir}")

if __name__ == "__main__":
    main()